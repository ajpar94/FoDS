{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vg5Ko3WDF7BG"
   },
   "source": [
    "# Exercise Sheet 10: MNIST contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO6wZraGGDd2"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O7c6C2Mu-FA2",
    "outputId": "6088fa71-ad5a-4eb3-de72-43ce36e0311e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKULtCXAGIs2"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HD_m2daY-WAx"
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, classes = range(10)):\n",
    "    \"\"\" Load data from mnist dataset stored in csv format. \n",
    "        Rows correspond to examples.\n",
    "        First column are the labels, all other columns constitute the data.\n",
    "        Each image is 28 x 28 stored as 784-dim. vector .\n",
    "        Input: \n",
    "            path      path to csv file\n",
    "            classes   list of classes to extract\n",
    "        Output:\n",
    "            data      design matrix holding the images\n",
    "            labels    array of corresponding labels\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    lab = np.array(df.iloc[:,0])\n",
    "    dat = np.array(df.iloc[:,1:])\n",
    "    ind = [c in classes for c in lab]\n",
    "    data = dat[ind,:]\n",
    "    labels = lab[ind]\n",
    "\n",
    "    return data,labels\n",
    "\n",
    "\n",
    "def plot_mnist(x,y=None):\n",
    "    \"\"\" Plot an mnist image with its label.\n",
    "        Input:\n",
    "        x      784-dim. vector representing a grayscale image of size 28 x 28.\n",
    "    \"\"\"\n",
    "    img = np.reshape(x,(28,28))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    if y != None:\n",
    "        plt.title(\"Label: {}\".format(y))\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    \n",
    "\n",
    "def plot_mnist_multiple(X,y=None):\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    for i in range(20):\n",
    "        plt.subplot(2,10,i+1)\n",
    "        try:\n",
    "            plot_mnist(X[i], y[i])\n",
    "        except TypeError:\n",
    "            plot_mnist(X[i])\n",
    "\n",
    "        \n",
    "def rotate_augment(X, y):\n",
    "    \n",
    "    X_img = X.reshape(X.shape[0],28,28)\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    i =0\n",
    "    for x in X_img:\n",
    "        for angle in [-15, 0, 15]:\n",
    "            rot_x = rotate(x,angle)\n",
    "            X_aug.append(rot_x)\n",
    "            y_aug.append(y[i])\n",
    "        i +=1\n",
    "    y = np.array(y_aug)\n",
    "    X = np.array(X_aug)\n",
    "    X = X.reshape(X.shape[0], 784)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def make_model(n_neuron, n_layer, drop_rate, opt):\n",
    "    \n",
    "    model = None\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_neuron, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))                            \n",
    "    model.add(Dropout(drop_rate))\n",
    "  \n",
    "    for _ in range(n_layer - 1):\n",
    "        model.add(Dense(n_neuron))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(drop_rate))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "  \n",
    "    # compiling the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oyg4H1wgHR1l"
   },
   "source": [
    "## Part 1: Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhBHbvgvHc4e"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "GzXBaYMk-btb",
    "outputId": "0e800ecf-312d-4aec-e0cb-b487c28a7df9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAAEQCAYAAADoNpIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 20 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('mnist_small.csv')\n",
    "plot_mnist_multiple(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZaC9-HHoh4WO"
   },
   "outputs": [],
   "source": [
    "# Map pixels to [0, 1]\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BSuJz3tehOg8"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "X_train, y_train = rotate_augment(X_train, y_train)\n",
    "idx = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[idx], y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AHod08Xt-g77"
   },
   "outputs": [],
   "source": [
    "# One-Hot encode labels\n",
    "n_classes = 10\n",
    "Y_train = to_categorical(y_train, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VZStXI4OiGLv",
    "outputId": "d84be091-b51f-4ad4-bfb0-c3043f613ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (3000, 784)\n",
      "Y_train Shape: (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train Shape:', X_train.shape) \n",
    "print('Y_train Shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teOeeyc-HWMZ"
   },
   "source": [
    "### Model Selection\n",
    "For 32 different hyperparameter combinations\n",
    "\n",
    "*   Number of neurons in a hidden layer\n",
    "*   Number of hidden layer\n",
    "*   Dropout rate\n",
    "*   Optimizer\n",
    "*   Batch size\n",
    "\n",
    "We perform a 5-fold Cross-Validation and pick the model, which performs best.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4913
    },
    "colab_type": "code",
    "id": "Y6nN1A9O_Yns",
    "outputId": "f6d649c9-1ed8-4f14-b8e8-4e5486532027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 95.20%\n",
      "acc: 92.86%\n",
      "acc: 95.00%\n",
      "acc: 93.98%\n",
      "acc: 93.79%\n",
      "94.17% (+/- 0.85%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 94.04%\n",
      "acc: 92.52%\n",
      "acc: 91.83%\n",
      "acc: 92.64%\n",
      "acc: 92.95%\n",
      "92.80% (+/- 0.72%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.54%\n",
      "acc: 92.36%\n",
      "acc: 93.67%\n",
      "acc: 93.14%\n",
      "acc: 93.62%\n",
      "93.47% (+/- 0.71%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 94.21%\n",
      "acc: 91.20%\n",
      "acc: 93.17%\n",
      "acc: 93.48%\n",
      "acc: 93.29%\n",
      "93.07% (+/- 1.00%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 92.88%\n",
      "acc: 93.69%\n",
      "acc: 93.33%\n",
      "acc: 93.65%\n",
      "acc: 92.95%\n",
      "93.30% (+/- 0.34%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 94.21%\n",
      "acc: 92.52%\n",
      "acc: 93.00%\n",
      "acc: 93.48%\n",
      "acc: 93.96%\n",
      "93.43% (+/- 0.61%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 93.38%\n",
      "acc: 91.69%\n",
      "acc: 92.50%\n",
      "acc: 92.47%\n",
      "acc: 93.96%\n",
      "92.80% (+/- 0.79%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 93.21%\n",
      "acc: 92.52%\n",
      "acc: 92.00%\n",
      "acc: 92.98%\n",
      "acc: 92.95%\n",
      "92.73% (+/- 0.43%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 94.04%\n",
      "acc: 93.36%\n",
      "acc: 92.67%\n",
      "acc: 93.98%\n",
      "acc: 92.62%\n",
      "93.33% (+/- 0.61%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 95.03%\n",
      "acc: 92.36%\n",
      "acc: 93.50%\n",
      "acc: 95.32%\n",
      "acc: 93.79%\n",
      "94.00% (+/- 1.08%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.70%\n",
      "acc: 93.52%\n",
      "acc: 94.17%\n",
      "acc: 93.65%\n",
      "acc: 93.96%\n",
      "94.00% (+/- 0.42%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 94.54%\n",
      "acc: 92.69%\n",
      "acc: 93.83%\n",
      "acc: 92.98%\n",
      "acc: 94.46%\n",
      "93.70% (+/- 0.75%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 93.71%\n",
      "acc: 91.20%\n",
      "acc: 93.00%\n",
      "acc: 92.81%\n",
      "acc: 94.30%\n",
      "93.00% (+/- 1.05%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 93.87%\n",
      "acc: 93.19%\n",
      "acc: 93.00%\n",
      "acc: 92.64%\n",
      "acc: 92.95%\n",
      "93.13% (+/- 0.41%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 92.88%\n",
      "acc: 92.03%\n",
      "acc: 92.33%\n",
      "acc: 92.14%\n",
      "acc: 93.46%\n",
      "92.57% (+/- 0.53%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 256 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 93.87%\n",
      "acc: 92.86%\n",
      "acc: 92.33%\n",
      "acc: 91.81%\n",
      "acc: 94.13%\n",
      "93.00% (+/- 0.89%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 93.54%\n",
      "acc: 91.36%\n",
      "acc: 94.17%\n",
      "acc: 93.98%\n",
      "acc: 93.29%\n",
      "93.27% (+/- 1.00%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 92.38%\n",
      "acc: 92.69%\n",
      "acc: 92.83%\n",
      "acc: 91.30%\n",
      "acc: 95.30%\n",
      "92.90% (+/- 1.31%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.54%\n",
      "acc: 93.36%\n",
      "acc: 93.33%\n",
      "acc: 93.98%\n",
      "acc: 95.30%\n",
      "94.10% (+/- 0.75%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 93.71%\n",
      "acc: 94.19%\n",
      "acc: 93.67%\n",
      "acc: 93.48%\n",
      "acc: 93.79%\n",
      "93.77% (+/- 0.23%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 94.70%\n",
      "acc: 92.19%\n",
      "acc: 92.67%\n",
      "acc: 93.65%\n",
      "acc: 94.63%\n",
      "93.57% (+/- 1.01%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 93.38%\n",
      "acc: 91.36%\n",
      "acc: 93.00%\n",
      "acc: 93.81%\n",
      "acc: 94.63%\n",
      "93.24% (+/- 1.08%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.87%\n",
      "acc: 92.36%\n",
      "acc: 94.33%\n",
      "acc: 93.31%\n",
      "acc: 94.63%\n",
      "93.90% (+/- 0.94%)\n",
      "##########################################################\n",
      "2 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 94.37%\n",
      "acc: 93.36%\n",
      "acc: 93.67%\n",
      "acc: 93.48%\n",
      "acc: 94.80%\n",
      "93.93% (+/- 0.56%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 94.21%\n",
      "acc: 91.86%\n",
      "acc: 93.83%\n",
      "acc: 92.98%\n",
      "acc: 93.96%\n",
      "93.37% (+/- 0.86%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 94.87%\n",
      "acc: 94.02%\n",
      "acc: 93.83%\n",
      "acc: 93.65%\n",
      "acc: 94.30%\n",
      "94.13% (+/- 0.43%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.87%\n",
      "acc: 93.36%\n",
      "acc: 94.67%\n",
      "acc: 93.14%\n",
      "acc: 94.46%\n",
      "94.10% (+/- 0.71%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.25)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 94.54%\n",
      "acc: 94.19%\n",
      "acc: 93.67%\n",
      "acc: 93.14%\n",
      "acc: 94.46%\n",
      "94.00% (+/- 0.53%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 25\n",
      "acc: 94.21%\n",
      "acc: 93.85%\n",
      "acc: 92.33%\n",
      "acc: 93.81%\n",
      "acc: 94.46%\n",
      "93.73% (+/- 0.74%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adam, batch size: 50\n",
      "acc: 94.37%\n",
      "acc: 91.69%\n",
      "acc: 94.67%\n",
      "acc: 92.81%\n",
      "acc: 94.80%\n",
      "93.67% (+/- 1.22%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 25\n",
      "acc: 94.87%\n",
      "acc: 93.85%\n",
      "acc: 93.17%\n",
      "acc: 93.48%\n",
      "acc: 95.64%\n",
      "94.20% (+/- 0.92%)\n",
      "##########################################################\n",
      "3 hidden layer(s) with 512 neurons (Dropout: 0.50)\n",
      "Optimizer: adagrad, batch size: 50\n",
      "acc: 94.04%\n",
      "acc: 93.36%\n",
      "acc: 93.17%\n",
      "acc: 93.98%\n",
      "acc: 94.13%\n",
      "93.73% (+/- 0.39%)\n"
     ]
    }
   ],
   "source": [
    "# This takes very long to run ...\n",
    "n_neurons = [256, 512]\n",
    "n_layers = [2, 3]\n",
    "drop_rates = [0.25, 0.5]\n",
    "optimizers = ['adam', 'adagrad']\n",
    "batch_sizes = [25, 50]\n",
    "\n",
    "for n_neuron in n_neurons:\n",
    "    for n_layer in n_layers:\n",
    "        for drop_rate in drop_rates:\n",
    "            for opt in optimizers:\n",
    "                for batch in batch_sizes:\n",
    "                    \n",
    "                    print('##########################################################')\n",
    "                    print(\"%d hidden layer(s) with %d neurons (Dropout: %.2f)\" % (n_layer, n_neuron, drop_rate))\n",
    "                    print(\"Optimizer: %s, batch size: %d\" % (opt, batch))\n",
    "                    # 5-fold cross validation\n",
    "                    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "                    cvscores = []\n",
    "                    for train, test in kfold.split(X_train, y_train):\n",
    "                        # create model\n",
    "                        model = make_model(n_neuron, n_layer, drop_rate, opt)\n",
    "                        # Fit the model\n",
    "                        model.fit(X_train[train], Y_train[train], epochs=50, batch_size=batch, verbose=0)\n",
    "                        # evaluate the model\n",
    "                        scores = model.evaluate(X_train[test], Y_train[test], verbose=0)\n",
    "                        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "                        cvscores.append(scores[1] * 100)\n",
    "                    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "jgGTw42I_ft3",
    "outputId": "d1e9c4e8-49ba-435c-e36e-72da652d0123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_603 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_603 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_429 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_604 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_430 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_605 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_431 (Dropout)        (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_606 (Dense)            (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_606 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chosen_model = make_model(512, 3, 0.5, 'adagrad')\n",
    "chosen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "siO9NZQGCE_3",
    "outputId": "81e08ef2-8ffa-457f-b8ef-bd53db1f0604",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 19s - loss: 1.2422 - acc: 0.5937\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.6085 - acc: 0.7987\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.4347 - acc: 0.8627\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.3369 - acc: 0.8900\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2657 - acc: 0.9157\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2469 - acc: 0.9183\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2141 - acc: 0.9293\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.1928 - acc: 0.9380\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.1700 - acc: 0.9467\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.1398 - acc: 0.9540\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1436 - acc: 0.9560\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1181 - acc: 0.9603\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1200 - acc: 0.9613\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0968 - acc: 0.9657\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0937 - acc: 0.9697\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0930 - acc: 0.9707\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0842 - acc: 0.9713\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0817 - acc: 0.9733\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0717 - acc: 0.9777\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.0629 - acc: 0.9803\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0522 - acc: 0.9837\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0611 - acc: 0.9797\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0546 - acc: 0.9810\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.0407 - acc: 0.9897\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.0473 - acc: 0.9847\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.0590 - acc: 0.9810\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.0418 - acc: 0.9867\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.0343 - acc: 0.9897\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.0370 - acc: 0.9893\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.0415 - acc: 0.9860\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.0329 - acc: 0.9913\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.0340 - acc: 0.9880\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.0363 - acc: 0.9890\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.0281 - acc: 0.9910\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.0336 - acc: 0.9903\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.0327 - acc: 0.9903\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.0249 - acc: 0.9923\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.0324 - acc: 0.9890\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.0308 - acc: 0.9900\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.0286 - acc: 0.9927\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.0265 - acc: 0.9903\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.0226 - acc: 0.9937\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.0294 - acc: 0.9897\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.0272 - acc: 0.9927\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.0232 - acc: 0.9937\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.0261 - acc: 0.9920\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.0209 - acc: 0.9937\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.0204 - acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "history = chosen_model.fit(X_train, Y_train,\n",
    "                           batch_size=25,\n",
    "                           epochs=50,\n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DUOEWoFYEe-B"
   },
   "outputs": [],
   "source": [
    "chosen_model.save('model_mnist_512_3.h5py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9naKtQk1LnvV"
   },
   "source": [
    "## Part 2: Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Adq_27TlFDBb"
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, epochs=50):\n",
    "    \"\"\"\n",
    "    define and train a multilayer perceptron (MLP)\n",
    "    \"\"\"\n",
    "    # Map pixels to [0, 1]\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train /= 255\n",
    "    # Data augmentation\n",
    "    X_train, y_train = rotate_augment(X_train, y_train)\n",
    "    # shuffle\n",
    "    idx = np.random.permutation(len(X_train))\n",
    "    X_train, y_train = X_train[idx], y_train[idx]\n",
    "    # One-Hot encode labels\n",
    "    n_classes = 10\n",
    "    Y_train = to_categorical(y_train, n_classes)\n",
    "    \n",
    "    # define and compile model\n",
    "    model = make_model(512, 3, 0.5, 'adagrad')\n",
    "    # fit model\n",
    "    model.fit(X_train, Y_train, batch_size=25, epochs=epochs, verbose=2)\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "G08_E10_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
